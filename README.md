# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #5 выполнил(а):
- Хмелёва Виктория Сергеевна
- РИ210942
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы
Осуществить интеграцию экономической системы в проект Unity и обучить ML-Agent.

## Задание 1
### Изменить параметры файла yaml-агента и определить какие параметры и как влияют на обучение модели.

- Открыла проект Unity, добавила в проект ml-agents-release_19. Запустила проект и ознакомилась с его работой.
![2022-11-30](https://user-images.githubusercontent.com/106344305/204775937-e355d2c8-4f01-4033-b1fa-ce9408654b8d.png)
- Запустила Anaconda Prompt. Создала и активировала виртуальное пространство. Запустила сцену в Unity и обучение ML-Агента.

![image](https://user-images.githubusercontent.com/106344305/204784917-95bb790a-3a03-417d-8916-86edfe810bf9.png)

- Осуществилось обучение модели.
![image](https://user-images.githubusercontent.com/106344305/204785845-656358bb-8178-44df-9b14-a09838596079.png)
![image](https://user-images.githubusercontent.com/106344305/204788606-3ffbd2d9-ccf8-4d73-bd55-b9f99f164833.png)
- Результаты обучения модели были успешно сохранены.
![image](https://user-images.githubusercontent.com/106344305/204788741-e630ffd7-8303-40d8-8693-abd4769c238e.png)
- Построила графики для оценки результатов обучения в TensorBoard.
![image](https://user-images.githubusercontent.com/106344305/204803703-d7b4bafb-45f5-4cfc-906d-bbec0d735750.png)
-Начала изменять параметры в .yaml-файле:
- Изменила параметр strength, задав ему значение 5 (было 1).

![image](https://user-images.githubusercontent.com/106344305/204804341-929d9fbf-e3bc-49e2-8272-4661726b4142.png)

- Изменила параметр gamma, задав ему значение 0.5 (было 0.99).

![image](https://user-images.githubusercontent.com/106344305/204833420-3a9b330f-85e5-43fb-b2da-ab2594f6ca98.png)


- Изменила параметр batch_size, задав ему значение 500 (было 1024).

![image](https://user-images.githubusercontent.com/106344305/204811911-a42f881b-83dc-4790-9e4d-54cb0aac006a.png)

- Изменила параметр learning_rate, задав ему значение 2.0e-4 (было 3.0e-4).

![image](https://user-images.githubusercontent.com/106344305/204814033-ec1538cf-1dc2-480f-9a0f-344d456e3217.png)

- Изменила параметр time-horizon, задав ему значение 32 (было 64).

![image](https://user-images.githubusercontent.com/106344305/204816256-4c062519-ca3c-4034-acb2-adfe7f98b7cd.png)

- При увеличении параметра strength модель стала обучаться хуже. Награда становилась больше с меньшей скоростью, чем при тех параметрах, что были заданы с начала. При уменьшении параметров batch_size, learning_rate, gamma наблюдались примерно те же результаты - модель стала обучаться хуже. В случае с изменением параметров batch_size, learning_rate происходили резкие спады и подъемы значения награды. При изменении параметра time-horizon наблюдалось улучшение обучения модели.

## Задание 2
### Описать результаты, выведенные в TensorBoard. 
Ориентируясь на графики, полученные в предыдущем задании можно сделать следующие выводы:
- В первом графике можно увидеть, что модель успешно обучилась и на протяжении всего обучения получала награду 1.0 (Cumulative Reward). Значения потерь (Value Loss) были невелики и уменьшались, что означает корректную работу обучения ML-агента.

![image](https://user-images.githubusercontent.com/106344305/204803703-d7b4bafb-45f5-4cfc-906d-bbec0d735750.png)

- Во втором графике при увеличении параметра strength с 1.0 до 5.0 можно увидеть, что модель успешно обучалась, однако ей бы понадобилось больше итераций, чем в первом случае, чтобы стабильно начать зарабатывать награду 1.0. Значения потерь возросли, по сравнению с первым графиком, и не смогли уменьшиться до примлемого значения.

![image](https://user-images.githubusercontent.com/106344305/204804341-929d9fbf-e3bc-49e2-8272-4661726b4142.png)

- В третьем графике при уменьшении параметра gamma с 0.99 до 0.5 модель успешно обучалась, однако рост награды происходил не стабильно. Значения потерь также возросли, как и во втором случае, и резко уменьшались.

![image](https://user-images.githubusercontent.com/106344305/204833420-3a9b330f-85e5-43fb-b2da-ab2594f6ca98.png)

- В четвертом графике при уменьшении параметра batch_size с 1024 до 500 можно заметить, что обучение модели происходило нестабильно. Значения награды становились то больше, то меньше. Значения потерь были высокими и не сильно уменьшались при увеличении количества итераций.

![image](https://user-images.githubusercontent.com/106344305/204811911-a42f881b-83dc-4790-9e4d-54cb0aac006a.png)

- В пятом графике при уменьшении параметра learning_rate с 3.0e-4 до 2.0e-4 также не наблюдалось успешного обучения модели, в основном, значения награды на протяжении всего обучения падали. Однако значения потерь оказались не столь велики в сравнении с тремя предыдущими графиками.

![image](https://user-images.githubusercontent.com/106344305/204814033-ec1538cf-1dc2-480f-9a0f-344d456e3217.png)

- В шестом графике при уменьшении параметра time-horizon с до 64 до 32 можно увидеть успешное обучение модели, значение награды во время обучения росло. Значения потерь смогли уменьшиться до 0.
- 
![image](https://user-images.githubusercontent.com/106344305/204816256-4c062519-ca3c-4034-acb2-adfe7f98b7cd.png)

- Графики Episode Length (длина эпизода) и Policy Loss (потери политики) не сильно модифицировались при изменении параметров, т.к. не были затронуты параметры, влияющие на их отображение. 



## Выводы

- В ходе данной работы я осуществила интеграцию экономической системы в проект Unity и обучила ML-Agent. Было произведено обучение модели 

| Plugin | README |
| ------ | ------ |
| Dropbox | [plugins/dropbox/README.md][PlDb] |
| GitHub | [plugins/github/README.md][PlGh] |
| Google Drive | [plugins/googledrive/README.md][PlGd] |
| OneDrive | [plugins/onedrive/README.md][PlOd] |
| Medium | [plugins/medium/README.md][PlMe] |
| Google Analytics | [plugins/googleanalytics/README.md][PlGa] |

## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
